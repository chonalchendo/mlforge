# Storage Backends

mlforge supports multiple storage backends for persisting built features. Configure backends via `mlforge.yaml` profiles or directly in your Definitions.

## Configuration via Profiles

The recommended way to configure storage is via `mlforge.yaml`:

```yaml
default_profile: dev

profiles:
  dev:
    offline_store:
      KIND: local
      path: ./feature_store

  staging:
    offline_store:
      KIND: s3
      bucket: staging-features
      prefix: v1

  production:
    offline_store:
      KIND: s3
      bucket: prod-features
      prefix: v1
      region: us-west-2
```

Switch between profiles:

```bash
mlforge build --profile production
# or
export MLFORGE_PROFILE=production
mlforge build
```

---

## LocalStore

The default storage backend that writes features to the local filesystem as Parquet files.

### Profile Configuration

```yaml
profiles:
  dev:
    offline_store:
      KIND: local
      path: ./feature_store
```

### Python Configuration

```python
import mlforge as mlf

defs = mlf.Definitions(
    name="my-project",
    features=[features],
    offline_store=mlf.LocalStore(path="./feature_store")
)
```

### Storage Structure

Features are stored in a versioned directory structure:

```
feature_store/
├── user_spend/
│   ├── 1.0.0/
│   │   ├── data.parquet          # Feature data
│   │   └── .meta.json            # Version metadata
│   ├── 1.0.1/
│   │   ├── data.parquet
│   │   └── .meta.json
│   ├── _latest.json              # Pointer to latest version
│   └── .gitignore                # Auto-generated
└── merchant_revenue/
    ├── 1.0.0/
    │   ├── data.parquet
    │   └── .meta.json
    └── _latest.json
```

**Key files:**

| File | Purpose |
|------|---------|
| `data.parquet` | Materialized feature data |
| `.meta.json` | Version metadata (schema, config, hashes) |
| `_latest.json` | Pointer to latest version |
| `.gitignore` | Excludes `*/data.parquet` for Git |

### Git Integration

LocalStore auto-generates `.gitignore` to exclude data files:

```gitignore
# Auto-generated by mlforge
*/data.parquet
```

Commit metadata to Git, rebuild data with `mlforge sync`:

```bash
git pull
mlforge sync  # Rebuilds data from metadata
```

### When to Use

- Local development and debugging
- Small datasets that fit on disk
- CI/CD pipelines with ephemeral storage
- Single-machine deployments

---

## S3Store

Cloud storage backend for Amazon S3.

### Profile Configuration

```yaml
profiles:
  production:
    offline_store:
      KIND: s3
      bucket: my-features
      prefix: prod/v1
      region: us-west-2  # optional
```

### Python Configuration

```python
import mlforge as mlf

defs = mlf.Definitions(
    name="my-project",
    features=[features],
    offline_store=mlf.S3Store(
        bucket="my-features",
        prefix="prod/v1",
        region="us-west-2"
    )
)
```

### AWS Credentials

S3Store uses standard AWS credential resolution:

=== "Environment Variables"
    ```bash
    export AWS_ACCESS_KEY_ID=AKIAIOSFODNN7EXAMPLE
    export AWS_SECRET_ACCESS_KEY=wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY
    export AWS_DEFAULT_REGION=us-west-2
    ```

=== "AWS CLI"
    ```bash
    aws configure
    ```

=== "IAM Role"
    When running on AWS (EC2/ECS/Lambda), use IAM roles - no credentials needed.

### IAM Policy

Minimal policy for feature store access:

```json
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Action": [
        "s3:GetObject",
        "s3:PutObject",
        "s3:DeleteObject",
        "s3:ListBucket"
      ],
      "Resource": [
        "arn:aws:s3:::my-features",
        "arn:aws:s3:::my-features/*"
      ]
    }
  ]
}
```

??? info "Read-Only Policy"
    For production retrieval:
    ```json
    {
      "Version": "2012-10-17",
      "Statement": [
        {
          "Effect": "Allow",
          "Action": ["s3:GetObject", "s3:ListBucket"],
          "Resource": [
            "arn:aws:s3:::my-features",
            "arn:aws:s3:::my-features/*"
          ]
        }
      ]
    }
    ```

### When to Use

- Production deployments
- Team collaboration (shared storage)
- Large datasets
- Multi-environment workflows (dev/staging/prod prefixes)

---

## GCSStore

Cloud storage backend for Google Cloud Storage.

### Profile Configuration

```yaml
profiles:
  production:
    offline_store:
      KIND: gcs
      bucket: my-features
      prefix: prod/v1
```

### Python Configuration

```python
import mlforge as mlf

defs = mlf.Definitions(
    name="my-project",
    features=[features],
    offline_store=mlf.GCSStore(
        bucket="my-features",
        prefix="prod/v1"
    )
)
```

### Installation

GCSStore requires the `gcs` extra:

```bash
pip install mlforge-sdk[gcs]
```

### Authentication

GCSStore uses standard Google Cloud credential resolution:

=== "Application Default Credentials"
    ```bash
    gcloud auth application-default login
    ```

=== "Service Account"
    ```bash
    export GOOGLE_APPLICATION_CREDENTIALS=/path/to/service-account.json
    ```

=== "Workload Identity"
    When running on GCP (GKE, Cloud Run), use Workload Identity - no credentials needed.

### IAM Roles

Grant the `Storage Object Admin` role for full access, or `Storage Object Viewer` for read-only:

```bash
gcloud storage buckets add-iam-policy-binding gs://my-features \
  --member="serviceAccount:my-sa@project.iam.gserviceaccount.com" \
  --role="roles/storage.objectAdmin"
```

### When to Use

- GCP-based deployments
- Integration with BigQuery, Vertex AI
- Teams already using GCP

---

## Multi-Environment Setup

Use profiles to manage different environments:

```yaml
# mlforge.yaml
default_profile: dev

profiles:
  dev:
    offline_store:
      KIND: local
      path: ./feature_store

  staging:
    offline_store:
      KIND: s3
      bucket: staging-features
      prefix: features

  production:
    offline_store:
      KIND: s3
      bucket: ${oc.env:PROD_BUCKET}
      prefix: features
      region: ${oc.env:AWS_REGION}
```

Build to different environments:

```bash
# Development
mlforge build

# Staging
mlforge build --profile staging

# Production (with env vars)
PROD_BUCKET=prod-features AWS_REGION=us-west-2 mlforge build --profile production
```

Validate profile connectivity:

```bash
mlforge profile --validate
mlforge profile --profile production --validate
```

---

## Performance Considerations

| Backend | Pros | Cons |
|---------|------|------|
| **LocalStore** | Fast (no network), simple setup, works offline | Limited by disk, not distributed |
| **S3Store** | Unlimited storage, high durability, accessible anywhere | Network latency, transfer costs |
| **GCSStore** | GCP integration, unlimited storage | Network latency, GCP-only |

### Optimization Tips

1. **Colocate compute and storage** - Same region reduces latency
2. **Batch builds** - Build all features in one `mlforge build` call
3. **Use IAM roles** - Avoid credential management on cloud platforms

---

## Next Steps

- [Online Stores](online-stores.md) - Configure Redis for real-time serving
- [Building Features](building-features.md) - Build features to storage
- [Retrieving Features](retrieving-features.md) - Read features from storage
- [Store API Reference](../api/store.md) - Detailed API documentation
